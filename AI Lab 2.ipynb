{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import math\n",
    "from random import random, randint, shuffle\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression as PythonLogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier as PythonKNN\n",
    "from sklearn.svm import SVC as PythonSVM\n",
    "from sklearn.tree import DecisionTreeClassifier as PythonDecisionTree\n",
    "from sklearn.ensemble import RandomForestClassifier as PythonRandomForest\n",
    "from sklearn import metrics\n",
    "from collections import namedtuple\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, epochs=100):\n",
    "        self.__coefs = np.array([])\n",
    "        self.__predictor = None\n",
    "        self.__epochs = epochs\n",
    "\n",
    "    def fit(self, features, targets):\n",
    "        class LikehoodFunction:\n",
    "            def __init__(self, x, y):\n",
    "                one = np.array([1] * x.shape[0])\n",
    "                self._x = np.append(one[:,np.newaxis], x, axis=1)\n",
    "                self._y = y\n",
    "\n",
    "            def __call__(self, b):\n",
    "                poly = np.sum(self._x * b, axis=1)\n",
    "                prob = 1 / (1 + np.exp(-poly))\n",
    "                return -(np.sum(self._y * np.log(prob) + (1 - self._y) * np.log(1 - prob)))\n",
    "\n",
    "        class LikehoodFunctionJacobian(LikehoodFunction):\n",
    "            def __call__(self, b):\n",
    "                poly = np.sum(self._x * b, axis=1)\n",
    "                mul = np.sum(self._y - 1 / (1 + np.exp(-poly)))\n",
    "                return -b * mul\n",
    "\n",
    "        class LikehoodFunctionHessian(LikehoodFunction):\n",
    "            def __call__(self, b):\n",
    "                poly = np.sum(self._x * b, axis=1)\n",
    "                mul = np.sum(np.exp(-poly) / np.power(1 + np.exp(-poly), 2))\n",
    "                ans = b[:,np.newaxis] * b\n",
    "                return ans * mul\n",
    "\n",
    "        class Predictor:\n",
    "            def __init__(self, b):\n",
    "                self.__b = b\n",
    "\n",
    "            def __call__(self, x):\n",
    "                one = np.array([1] * x.shape[0])\n",
    "                xa = np.append(one[:,np.newaxis], x, axis=1)\n",
    "                poly = np.sum(xa * self.__b, axis=1)\n",
    "                return 1 / (1 + np.exp(-poly))\n",
    "\n",
    "        start = np.random.random(features.shape[1] + 1) - 0.5\n",
    "\n",
    "        self.__coefs = minimize(\n",
    "            LikehoodFunction(features, targets), start, method='trust-ncg', \n",
    "            jac=LikehoodFunctionJacobian(features, targets),\n",
    "            hess=LikehoodFunctionHessian(features, targets),\n",
    "            options={'maxiter': self.__epochs}\n",
    "        ).x\n",
    "\n",
    "        self.__predictor = Predictor(self.__coefs)\n",
    "        self.__threshold = 0.5\n",
    "\n",
    "    def predict(self, features):\n",
    "        if not self.__predictor is None and self.__coefs.size == features.shape[1] + 1:\n",
    "            return (self.__predictor(features) > self.__threshold) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KDTreeNode:\n",
    "    __Neighbour = namedtuple(\"Neighbour\", [\"dist_sq\", \"value\", \"class_id\"])\n",
    "\n",
    "    def __init__(self, value=None, class_id=None, coord=0, parent=None, left=None, right=None):\n",
    "        self.value = value\n",
    "        self.class_id = class_id\n",
    "        self.coord = coord\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.parent = parent\n",
    "        \n",
    "    def find_closest_k(self, target, k):\n",
    "        ans = []\n",
    "\n",
    "        if target[self.coord] >= self.value[self.coord]:\n",
    "            if not self.right is None:\n",
    "                ans = self.right.find_closest_k(target, k)\n",
    "            neighbour = self.left\n",
    "        else:\n",
    "            if not self.left is None:\n",
    "                ans = self.left.find_closest_k(target, k)\n",
    "            neighbour = self.right\n",
    "\n",
    "        curr_dist = np.sum(np.power(target - self.value, 2))\n",
    "\n",
    "        if len(ans) == 0 or curr_dist < heapq.nlargest(1, ans)[0].dist_sq:\n",
    "            pushed = self.__Neighbour(curr_dist, self.value, self.class_id)\n",
    "            if len(ans) < k:\n",
    "                heapq.heappush(ans, pushed)\n",
    "            else:\n",
    "                heapq.heappushpop(ans, pushed)\n",
    "\n",
    "        dif = np.power(target[self.coord] - self.value[self.coord], 2)\n",
    "\n",
    "        if not neighbour is None and dif <= heapq.nlargest(1, ans)[0].dist_sq:\n",
    "            ans += neighbour.find_closest_k(target, k)\n",
    "            heapq.heapify(ans)\n",
    "            if len(ans) > k:\n",
    "                ans = heapq.nsmallest(k, ans)\n",
    "                heapq.heapify(ans)\n",
    "\n",
    "        return ans\n",
    "\n",
    "class KDTree:\n",
    "    def __init__(self, numbers=None, classes=None):\n",
    "        if not numbers is None and not classes is None:\n",
    "            self.__root = self.__construct(numbers, classes, 0, len(numbers) - 1, None)\n",
    "        else:\n",
    "            self.__root = None\n",
    "\n",
    "    def __construct(self, numbers, classes, left, right, parent):\n",
    "        if left > right:\n",
    "            return None\n",
    "\n",
    "        if left == right:\n",
    "            return KDTreeNode(\n",
    "                value=numbers[left],\n",
    "                class_id=classes[left]\n",
    "            )\n",
    "\n",
    "        max_diffed_coords_ind = np.argmax([len(np.unique(i)) for i in numbers[left:right + 1].transpose()])\n",
    "\n",
    "        median = (left + right) // 2\n",
    "        while median > left and numbers[median, max_diffed_coords_ind] == numbers[median - 1, max_diffed_coords_ind]:\n",
    "            median -= 1\n",
    "\n",
    "        ans = KDTreeNode(\n",
    "            coord=max_diffed_coords_ind,\n",
    "            value=numbers[median],\n",
    "            class_id=classes[median],\n",
    "            parent=parent\n",
    "        )\n",
    "\n",
    "        ans.left = self.__construct(numbers, classes, left, median - 1, ans)\n",
    "        ans.right = self.__construct(numbers, classes, median + 1, right, ans)\n",
    "\n",
    "        return ans\n",
    "\n",
    "    def find_closest_k(self, target, k):\n",
    "        return self.__root.find_closest_k(target, k)\n",
    "\n",
    "    def empty(self):\n",
    "        return self.__root is None\n",
    "\n",
    "class KNN:\n",
    "    def __init__(self, k=50):\n",
    "        self.__tree = KDTree()\n",
    "        self.__k = k\n",
    "\n",
    "    def fit(self, features, targets):\n",
    "        self.__tree = KDTree(features, targets)\n",
    "\n",
    "    def predict(self, points):\n",
    "        ans = np.array([])\n",
    "        for point in points:\n",
    "            res = self.__tree.find_closest_k(point, self.__k)\n",
    "\n",
    "            weights = {}\n",
    "            for neighbour in res:\n",
    "                if not neighbour.class_id in weights:\n",
    "                    weights[neighbour.class_id] = 0\n",
    "                weights[neighbour.class_id] += 1 / neighbour.dist_sq\n",
    "\n",
    "            res_class = None\n",
    "            for class_id in weights:\n",
    "                if res_class is None or weights[res_class] < weights[class_id]:\n",
    "                    res_class = class_id\n",
    "\n",
    "            ans = np.append(ans, res_class)\n",
    "\n",
    "        return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM():\n",
    "    def __init__(self, epochs=5, a=0.5):\n",
    "        self.__epochs = epochs\n",
    "        self.__a = a\n",
    "        self.__predictor = None\n",
    "\n",
    "    def fit(self, features, targets):\n",
    "        class Q:\n",
    "            def __init__(self, x, y, a):\n",
    "                one = np.array([1] * x.shape[0])\n",
    "                self._x = np.append(one[:,np.newaxis], x, axis=1)\n",
    "                self._y = y\n",
    "                self._a = a\n",
    "                self._i = 0\n",
    "\n",
    "            def _iterate(self):\n",
    "                self._i += 1\n",
    "                if self._i == len(self._x):\n",
    "                    self._i = 0\n",
    "\n",
    "            def __call__(self, w):\n",
    "                ans = max(0., 1. - self._y[self._i] * np.sum(w * self._x[self._i])) + self._a * np.sum(w * w) / 2\n",
    "                self._iterate()\n",
    "                return ans\n",
    "\n",
    "        class QJac(Q):\n",
    "            def __call__(self, w):\n",
    "                if self._y[self._i] * np.sum(w * self._x[self._i]) < 1:\n",
    "                    ans = self._a * w - self._y[self._i] * self._x[self._i]\n",
    "                else:\n",
    "                    ans = self._a * w\n",
    "                self._iterate()\n",
    "                return ans\n",
    "\n",
    "        class Predictor:\n",
    "            def __init__(self, w):\n",
    "                self.__w = w\n",
    "\n",
    "            def __call__(self, x):\n",
    "                one = np.array([1] * x.shape[0])\n",
    "                xa = np.append(one[:,np.newaxis], x, axis=1)\n",
    "                return np.sum(self.__w * xa, axis=1)\n",
    "\n",
    "        start = np.random.random(features.shape[1] + 1) - 0.5\n",
    "\n",
    "        q_func = Q(features, targets, self.__a)\n",
    "        q_jac = QJac(features, targets, self.__a)\n",
    "\n",
    "        for i in range(self.__epochs):\n",
    "            for j in range(features.shape[0]):\n",
    "                self.__coefs = minimize(\n",
    "                    q_func, start, method='CG', \n",
    "                    jac=q_jac,\n",
    "                    options={'maxiter': 1}\n",
    "                ).x\n",
    "\n",
    "        self.__predictor = Predictor(self.__coefs)\n",
    "\n",
    "    def predict(self, features):\n",
    "        if not self.__predictor is None and self.__coefs.size == features.shape[1] + 1:\n",
    "            return (self.__predictor(features) > 0) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeLeaf:\n",
    "    def __init__(self, decision):\n",
    "        self.__decision = decision\n",
    "\n",
    "    def predict(self, point):\n",
    "        return self.__decision\n",
    "\n",
    "class DecisionTreeNode:\n",
    "    def __init__(self, feature, separator, left, right):\n",
    "        self.__feature = feature\n",
    "        self.__separator = separator\n",
    "        self.__left = left\n",
    "        self.__right = right\n",
    "\n",
    "    def predict(self, point):\n",
    "        if point[self.__feature] <= self.__separator:\n",
    "            return self.__left.predict(point)\n",
    "        else:\n",
    "            return self.__right.predict(point)\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, depth=None):\n",
    "        self.__root = None\n",
    "        self.__depth = depth\n",
    "\n",
    "    def fit(self, features, targets):\n",
    "        self.__root = self.__construct(features, targets)\n",
    "\n",
    "    def predict(self, points):\n",
    "        if self.__root is not None:\n",
    "            ans = []\n",
    "            for point in points:\n",
    "                ans.append(self.__root.predict(point))\n",
    "            return np.array(ans)\n",
    "\n",
    "    def __construct(self, features, targets, depth=0):\n",
    "        unique_targets = np.unique(targets)\n",
    "        if unique_targets.size == 1:\n",
    "            return DecisionTreeLeaf(unique_targets[0])\n",
    "\n",
    "        if not self.__depth is None and self.__depth == depth:\n",
    "            return DecisionTreeLeaf(self.__get_freq_target(targets))\n",
    "\n",
    "        max_gain = None\n",
    "        for i in range(features.shape[1]):\n",
    "            curr_gain, curr_sep = self.__information_gain(features[:,i], targets)\n",
    "            if max_gain is None or curr_gain > max_gain:\n",
    "                max_ind = i\n",
    "                max_sep = curr_sep\n",
    "                max_gain = curr_gain\n",
    "\n",
    "        left = ([], [])\n",
    "        right = ([], [])\n",
    "        for i in range(features.shape[0]):\n",
    "            if features[i, max_ind] <= max_sep:\n",
    "                left[0].append(features[i])\n",
    "                left[1].append(targets[i])\n",
    "            else:\n",
    "                right[0].append(features[i])\n",
    "                right[1].append(targets[i])\n",
    "\n",
    "        if len(left[0]) == 0 or len(right[0]) == 0:\n",
    "            return DecisionTreeLeaf(self.__get_freq_target(targets))\n",
    "\n",
    "        return DecisionTreeNode(\n",
    "            feature=max_ind,\n",
    "            separator=max_sep,\n",
    "            left=self.__construct(np.array(left[0]), np.array(left[1]), depth + 1),\n",
    "            right=self.__construct(np.array(right[0]), np.array(right[1]), depth + 1)\n",
    "        \n",
    "        )\n",
    "\n",
    "    def __information_gain(self, features, targets):\n",
    "        targets_counts = {}\n",
    "        for target in targets:\n",
    "            if target not in targets_counts:\n",
    "                targets_counts[target] = 0\n",
    "            targets_counts[target] += 1\n",
    "\n",
    "        sorted_targets_inds = np.argsort(features)\n",
    "        values = np.sort(features)\n",
    "\n",
    "        optimal_separator = None\n",
    "        curr_targets_counts = {}\n",
    "        for target in targets_counts:\n",
    "            curr_targets_counts[target] = 0\n",
    "\n",
    "        for i in range(len(targets) - 1):\n",
    "            curr_targets_counts[targets[sorted_targets_inds[i]]] += 1\n",
    "\n",
    "            curr_information_ammount = 0\n",
    "            for target in targets_counts:\n",
    "                p1 = curr_targets_counts[target] / (i + 1)\n",
    "                p2 = (targets_counts[target] - curr_targets_counts[target]) / (len(targets) - (i + 1))\n",
    "\n",
    "                if p1 > 0:\n",
    "                    curr_information_ammount -= p1 * math.log(p1, 2)\n",
    "                if p2 > 0:\n",
    "                    curr_information_ammount -= p2 * math.log(p2, 2)\n",
    "\n",
    "            if optimal_separator is None or curr_information_ammount < optimal_information_ammount:\n",
    "                optimal_separator = values[i]\n",
    "                optimal_information_ammount = curr_information_ammount\n",
    "\n",
    "        base_information_ammount = 0\n",
    "        for target_count in targets_counts.values():\n",
    "            p = target_count / len(features)\n",
    "            base_information_ammount -= p * math.log(p, 2)\n",
    "\n",
    "        return (base_information_ammount - optimal_information_ammount, optimal_separator)\n",
    "\n",
    "    def __get_freq_target(self, targets):\n",
    "        targets_count = {}\n",
    "\n",
    "        for target in targets:\n",
    "            if not target in targets_count:\n",
    "                targets_count[target] = 0\n",
    "            targets_count[target] += 1\n",
    "\n",
    "        best_target = None\n",
    "        for curr_target in targets_count:\n",
    "            if best_target is None or targets_count[best_target] < targets_count[curr_target]:\n",
    "                best_target = curr_target\n",
    "\n",
    "        return best_target\n",
    "\n",
    "class RandomForest:\n",
    "    def __init__(self, trees_count=None, depth=None, effective_factors=None):\n",
    "        self.__trees_count = trees_count\n",
    "        self.__depth = depth\n",
    "        self.__effective_factors = effective_factors\n",
    "        self.__trees = None\n",
    "\n",
    "    def fit(self, features, targets):\n",
    "        if self.__effective_factors is None:\n",
    "            self.__effective_factors = math.floor(math.sqrt(features.shape[1]))\n",
    "        if self.__effective_factors > features.shape[1]:\n",
    "            self.__effective_factors = features.shape[1]\n",
    "\n",
    "        if self.__trees_count is None:\n",
    "            self.__trees_count = math.ceil(math.sqrt(features.shape[1]))\n",
    "\n",
    "        self.__trees = []\n",
    "\n",
    "        for i in range(self.__trees_count):\n",
    "            points_inds = [randint(0, features.shape[0] - 1) for i in range(features.shape[0])]\n",
    "            tmp = [i for i in range(features.shape[1])]\n",
    "            shuffle(tmp)\n",
    "            targets_inds = sorted(tmp[:self.__effective_factors])\n",
    "\n",
    "            curr_points = []\n",
    "            curr_targets = []\n",
    "            for ind in points_inds:\n",
    "                curr_points.append(features[ind])\n",
    "                curr_targets.append(targets[ind])\n",
    "\n",
    "            curr_points = np.array(curr_points)\n",
    "            curr_targets = np.array(curr_targets)\n",
    "\n",
    "            trunc_factors = curr_points[:, targets_inds[0], np.newaxis]\n",
    "            for ind in targets_inds[1:]:\n",
    "                np.append(trunc_factors, curr_points[:, ind, np.newaxis], axis=1)\n",
    "\n",
    "            curr_tree = DecisionTree(self.__depth)\n",
    "            curr_tree.fit(trunc_factors, curr_targets)\n",
    "            self.__trees.append(curr_tree)\n",
    "\n",
    "    def predict(self, points):\n",
    "        ans = []\n",
    "        for point in points:\n",
    "            votes = {}\n",
    "            for tree in self.__trees:\n",
    "                pred = tree.predict([point])[0]\n",
    "                if pred not in votes:\n",
    "                    votes[pred] = 0\n",
    "                votes[pred] += 1\n",
    "\n",
    "            predicted_class = None\n",
    "            for class_id, votes_count in votes.items():\n",
    "                if predicted_class is None or votes[predicted_class] < votes_count:\n",
    "                    predicted_class = class_id\n",
    "\n",
    "            ans.append(predicted_class)\n",
    "        return np.array(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(path):\n",
    "    csv_path = os.path.join(path)\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_csv(\"E:\\Labs\\AI\\Datasets\\weather_ready_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = np.random.rand(len(data))\n",
    "sampling_rate = 0.8\n",
    "training_mask = probs < sampling_rate\n",
    "test_mask = probs >= sampling_rate\n",
    "\n",
    "learn_data = data[training_mask]\n",
    "learn_features = learn_data.drop(\"RainTomorrow\", axis='columns').to_numpy()\n",
    "learn_targets = learn_data[\"RainTomorrow\"].to_numpy()\n",
    "\n",
    "test_data = data[test_mask]\n",
    "test_features = test_data.drop(\"RainTomorrow\", axis='columns').to_numpy()\n",
    "test_targets = test_data[\"RainTomorrow\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_and_calc_metrics(model, learn_features, learn_targets, test_features, test_targets, name):\n",
    "    model.fit(learn_features, learn_targets)\n",
    "    res = model.predict(test_features)\n",
    "    print(\"{} metrics:\".format(name))\n",
    "    print(\"accuracy:\", metrics.accuracy_score(test_targets, res))\n",
    "    print(\"precision:\", metrics.precision_score(test_targets, res))\n",
    "    print(\"f1 score:\", metrics.f1_score(test_targets, res))\n",
    "    print(\"recall:\", metrics.recall_score(test_targets, res))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Labs\\conda\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: divide by zero encountered in log\n",
      "E:\\Labs\\conda\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My logistic regression metrics:\n",
      "accuracy: 0.773655763021199\n",
      "precision: 0.773655763021199\n",
      "f1 score: 0.8723854754130801\n",
      "recall: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn_and_calc_metrics(LogisticRegression(), learn_features, learn_targets, test_features, test_targets, \"My logistic regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python logistic regression metrics:\n",
      "accuracy: 0.773655763021199\n",
      "precision: 0.773655763021199\n",
      "f1 score: 0.8723854754130801\n",
      "recall: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn_and_calc_metrics(PythonLogisticRegression(), learn_features, learn_targets, test_features, test_targets, \"Python logistic regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My KNN metrics:\n",
      "accuracy: 0.717391304347826\n",
      "precision: 0.808695652173913\n",
      "f1 score: 0.8266666666666667\n",
      "recall: 0.8454545454545455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_sampling_rate = 0.01\n",
    "\n",
    "knn_learn_probs = np.random.rand(len(learn_features))\n",
    "taken_mask = knn_learn_probs < knn_sampling_rate\n",
    "knn_learn_features = learn_features[taken_mask]\n",
    "knn_learn_targets = learn_targets[taken_mask]\n",
    "\n",
    "knn_test_probs = np.random.rand(len(test_features))\n",
    "taken_mask = knn_test_probs < knn_sampling_rate\n",
    "knn_test_features = test_features[taken_mask]\n",
    "knn_test_targets = test_targets[taken_mask]\n",
    "\n",
    "learn_and_calc_metrics(KNN(), knn_learn_features, knn_learn_targets, knn_test_features, knn_test_targets, \"My KNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python KNN metrics:\n",
      "accuracy: 0.7956619401937386\n",
      "precision: 0.8395645802805107\n",
      "f1 score: 0.8732363699703884\n",
      "recall: 0.9097219071814181\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn_and_calc_metrics(PythonKNN(), learn_features, learn_targets, test_features, test_targets, \"Python KNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My SVM metrics:\n",
      "accuracy: 0.773655763021199\n",
      "precision: 0.773655763021199\n",
      "f1 score: 0.8723854754130801\n",
      "recall: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn_and_calc_metrics(SVM(1), learn_features, learn_targets, test_features, test_targets, \"My SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Labs\\conda\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python SVM metrics:\n",
      "accuracy: 0.6251579390706163\n",
      "precision: 0.7757875831270327\n",
      "f1 score: 0.7495544508019886\n",
      "recall: 0.7250374268475253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn_and_calc_metrics(PythonSVM(max_iter=1000), learn_features, learn_targets, test_features, test_targets, \"Python SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My decision tree metrics:\n",
      "accuracy: 1.0\n",
      "precision: 1.0\n",
      "f1 score: 1.0\n",
      "recall: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn_and_calc_metrics(DecisionTree(), learn_features, learn_targets, test_features, test_targets, \"My decision tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python decision tree metrics:\n",
      "accuracy: 1.0\n",
      "precision: 1.0\n",
      "f1 score: 1.0\n",
      "recall: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn_and_calc_metrics(PythonDecisionTree(), learn_features, learn_targets, test_features, test_targets, \"Python decision tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My random forest metrics:\n",
      "accuracy: 0.773655763021199\n",
      "precision: 0.773655763021199\n",
      "f1 score: 0.8723854754130801\n",
      "recall: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn_and_calc_metrics(RandomForest(depth=6), learn_features, learn_targets, test_features, test_targets, \"My random forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python random forest metrics:\n",
      "accuracy: 0.9999649024287519\n",
      "precision: 0.9999546361821811\n",
      "f1 score: 0.9999773175766099\n",
      "recall: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn_and_calc_metrics(PythonRandomForest(), learn_features, learn_targets, test_features, test_targets, \"Python random forest\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
